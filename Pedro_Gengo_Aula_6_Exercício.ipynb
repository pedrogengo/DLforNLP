{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pedro Gengo - Aula 6 - Exercício",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrogengo/DLforNLP/blob/main/Pedro_Gengo_Aula_6_Exerc%C3%ADcio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG5DT_dm6mk"
      },
      "source": [
        "# Notebook de referência \n",
        "\n",
        "Nome: Pedro Gabriel Gengo Lourenço"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owS9GdYIw-Xs",
        "outputId": "e018a3bf-080d-445a-c80d-c7b3494df0e5"
      },
      "source": [
        "!pip install neptune-client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neptune-client\n",
            "  Downloading neptune-client-0.11.0.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.16.0\n",
            "  Downloading boto3-1.18.46-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Collecting botocore<1.22.0,>=1.21.46\n",
            "  Downloading botocore-1.21.46-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.46->boto3>=1.16.0->neptune-client) (2.8.2)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Collecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Collecting jsonref\n",
            "  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading swagger_spec_validator-2.7.3-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2018.9)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Collecting strict-rfc3339\n",
            "  Downloading strict-rfc3339-0.7.tar.gz (17 kB)\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n",
            "Building wheels for collected packages: neptune-client, future, strict-rfc3339\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.11.0-py2.py3-none-any.whl size=465814 sha256=7a60e080b7710c7b871666886aa17c8c6da1d81bc797d671bbdb0ce2228f9038\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8e/62/53218bb22af6023b996288f379ea4844718519ba0f2acdf7b0\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=eb29005faa2e9b9b441414eff4403baa54a406bac7da993f52dbeb74b7fa8ed3\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-py3-none-any.whl size=18149 sha256=ac3470e9281b98b8fa6b31b55c108e886e6664f0593ee67a2c85e0896e33a78a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/1d/9f/2a74caecb81b8beb9a4fbe1754203d4b7cf42ef5d39e0d2311\n",
            "Successfully built neptune-client future strict-rfc3339\n",
            "Installing collected packages: webcolors, urllib3, strict-rfc3339, rfc3987, jmespath, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.24 PyJWT-2.1.0 boto3-1.18.46 botocore-1.21.46 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jmespath-0.10.0 jsonref-0.2 monotonic-1.6 neptune-client-0.11.0 rfc3987-1.3.8 s3transfer-0.5.0 simplejson-3.17.5 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 urllib3-1.25.11 webcolors-1.11.1 websocket-client-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojyVOubollcH"
      },
      "source": [
        "## Definindo os parametros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-YHxi_AllQZ"
      },
      "source": [
        "params = {\n",
        "    'vocabulary_size': 10000\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpAkifICdJo"
      },
      "source": [
        "# Fixando a seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozXD-xYCcrT"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import neptune.new as neptune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHeZ9nAOEB0U",
        "outputId": "86150284-1158-4a14-bc66-1e009bcb7366"
      },
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4a3bd79ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMi_Kq65fPM"
      },
      "source": [
        "Primeiro, fazemos download do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbnfzst5O3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d97c3f7-4b9c-4e32-868d-42af2ecb2474"
      },
      "source": [
        "!wget -nc http://files.fast.ai/data/aclImdb.tgz \n",
        "!tar -xzf aclImdb.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-23 10:59:04--  http://files.fast.ai/data/aclImdb.tgz\n",
            "Resolving files.fast.ai (files.fast.ai)... 104.26.3.19, 172.67.69.159, 104.26.2.19, ...\n",
            "Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.fast.ai/data/aclImdb.tgz [following]\n",
            "--2021-09-23 10:59:04--  https://files.fast.ai/data/aclImdb.tgz\n",
            "Connecting to files.fast.ai (files.fast.ai)|104.26.3.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145982645 (139M) [application/x-gtar-compressed]\n",
            "Saving to: ‘aclImdb.tgz’\n",
            "\n",
            "aclImdb.tgz         100%[===================>] 139.22M  9.41MB/s    in 16s     \n",
            "\n",
            "2021-09-23 10:59:21 (8.80 MB/s) - ‘aclImdb.tgz’ saved [145982645/145982645]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "## Carregando o dataset\n",
        "\n",
        "Criaremos uma divisão de treino (24k exemplos) e validação (1k exemplos) artificialmente.\n",
        "\n",
        "Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto.\n",
        "\n",
        "Neste exercicio, iremos usar apenas 1000 exemplos de validação e 1000 de teste pois precisamos executar uma inferencia do modelo para cada _palavra_ do dataset.\n",
        "\n",
        "Como o aprendizado é não supervisionado, não iremos utilizar os rótulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIN_xLI_TuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f15a753-5a68-4ba3-f7c2-d03ec87873be"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "max_valid = 1000\n",
        "max_test = 1000\n",
        "\n",
        "\n",
        "def load_texts(folder):\n",
        "    texts = []\n",
        "    for path in os.listdir(folder):\n",
        "        with open(os.path.join(folder, path)) as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "x_train_pos = load_texts('aclImdb/train/pos')\n",
        "x_train_neg = load_texts('aclImdb/train/neg')\n",
        "x_test_pos = load_texts('aclImdb/test/pos')\n",
        "x_test_neg = load_texts('aclImdb/test/neg')\n",
        "\n",
        "x_train = x_train_pos + x_train_neg\n",
        "x_test = x_test_pos + x_test_neg\n",
        "y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
        "y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
        "\n",
        "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
        "c = list(zip(x_train, y_train))\n",
        "random.shuffle(c)\n",
        "x_train, y_train = zip(*c)\n",
        "\n",
        "x_valid = x_train[-max_valid:]\n",
        "y_valid = y_train[-max_valid:]\n",
        "x_train = x_train[:-max_valid]\n",
        "y_train = y_train[:-max_valid]\n",
        "\n",
        "# Embaralhamos o teste para diminuir a chance de algum viés nos 1000 exemplos amostrados.\n",
        "c = list(zip(x_test, x_test))\n",
        "random.shuffle(c)\n",
        "x_test, x_test = zip(*c)\n",
        "x_test = x_test[:max_test]\n",
        "y_test = y_test[:max_test]\n",
        "\n",
        "print(len(x_train), 'amostras de treino.')\n",
        "print(len(x_valid), 'amostras de desenvolvimento.')\n",
        "print(len(x_test), 'amostras de teste.')\n",
        "\n",
        "print('3 primeiras amostras treino:')\n",
        "for x, y in zip(x_train[:3], y_train[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras treino:')\n",
        "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 primeiras amostras validação:')\n",
        "for x, y in zip(x_valid[:3], y_test[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras validação:')\n",
        "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
        "    print(y, x[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 amostras de treino.\n",
            "1000 amostras de desenvolvimento.\n",
            "1000 amostras de teste.\n",
            "3 primeiras amostras treino:\n",
            "False I wholeheartedly disagree with the other viewers of this wretched film. The only reason why I didn't\n",
            "False This film is really terrible. terrible as in it is a waste of 84 minutes of your life. Special effec\n",
            "True I realize that alot of people hate this movie, but i must admit that it is one of my favorites. I ha\n",
            "3 últimas amostras treino:\n",
            "False Yet another forgettable Warners foreign intrigue \"thriller,\" this is rendered even less enjoyable by\n",
            "False Cliché-ridden story of an impending divorce - or is it? - through the eyes of a 6 year-old child. Co\n",
            "False Okay, so the previews to this film only tells you that a rebellious young girl goes to live with her\n",
            "3 primeiras amostras validação:\n",
            "True I do agree that though this story by Melville just might be unfilmable, this isn't even a credible t\n",
            "True Very Slight Spoiler<br /><br /> This movie (despite being only on TV) is absolutely excellent. I did\n",
            "True Hot Millions is a great movie in every way. A fun, offbeat story with wonderful performances by four\n",
            "3 últimas amostras validação:\n",
            "True I grew up with this as my all-time favorite film. The special effects are incredible for the era, an\n",
            "True <br /><br />\"Burning Paradise\" is a combination of neo-Shaw Brothers action and Ringo Lam's urban cy\n",
            "True This film is, quite simply, brilliant. The cinematography is good, the acting superb and the story a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiLnZh8fKXvm",
        "outputId": "af7a3718-5a0c-4a7e-a66e-297963fee57d"
      },
      "source": [
        "print(f'Numero de palavras treino: {sum([len(item.split()) for item in x_train])}')\n",
        "print(f'Numero de palavras validação: {sum([len(item.split()) for item in x_valid])}')\n",
        "print(f'Numero de palavras teste: {sum([len(item.split()) for item in x_test])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de palavras treino: 5611955\n",
            "Numero de palavras validação: 232725\n",
            "Numero de palavras teste: 226558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLlaPgP0Z_D4"
      },
      "source": [
        "# Definindo o vocabulário\n",
        "\n",
        "Nessa etapa, definimos o vocabulário que será utilizado em todo o notebook. Para isso, passamos como limite de palavras o parâmetro configurado no início do notebook: *vocabulary_size*. Também definimos a função tokenize, que transforma um texto em uma lista de tokens unitários, caso esses tokens existam no vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIpp1C_qZ-QX",
        "outputId": "9805adcb-16cb-45e2-b66d-a2952111fa05"
      },
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "\n",
        "def tokenize(text, vocabulary=None):\n",
        "    return [token.lower() for token in re.compile('\\w+').findall(text) if vocabulary is None or vocabulary.get(token.lower()) is not None]\n",
        "\n",
        "\n",
        "vocabulary = collections.Counter([token for text in x_train for token in tokenize(text)]).most_common(params['vocabulary_size'])\n",
        "vocabulary = list(dict(vocabulary).keys())\n",
        "print('top 20 tokens do vocabulário:')\n",
        "print('\\n'.join(vocabulary[:20]))\n",
        "\n",
        "vocabulary = {token: i for i, token in enumerate(vocabulary)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 20 tokens do vocabulário:\n",
            "the\n",
            "and\n",
            "a\n",
            "of\n",
            "to\n",
            "is\n",
            "br\n",
            "it\n",
            "in\n",
            "i\n",
            "this\n",
            "that\n",
            "s\n",
            "was\n",
            "as\n",
            "for\n",
            "with\n",
            "movie\n",
            "but\n",
            "film\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTV4Yx6LFDM"
      },
      "source": [
        "# Criando os datasets\n",
        "\n",
        "Para o treinamento do Word2Vec (CBOW), é necessário que nosso conjunto de treinamento seja formado por:\n",
        "\n",
        "- target: tokens que queremos prever dado sua vizinhança;\n",
        "- features: lista de tokens passados e futuros do token target.\n",
        "\n",
        "Ou seja, precisamos criar uma janela em cima do token target. Dessa forma, na definição da classe Dataset que será usada no experimento, o que foi feito foi aplicar o conceito de \"convolução\" de redes convolucionais, para o cenário de texto. Um ponto muito importante é: o conjunto total *features + target* sempre terá tamanho ímpar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v3CGMzIMDJn"
      },
      "source": [
        "def unify_text(texts, vocabulary=None):\n",
        "  flatten_texts = []\n",
        "  for text in texts:\n",
        "    flatten_texts.extend(tokenize(text, vocabulary))\n",
        "  return flatten_texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMeddLdmMD2U"
      },
      "source": [
        "class DatasetSlidingWindow(Dataset):\n",
        "  def __init__(self, window_size, vocab, flatten_tokens):\n",
        "    self.window_size = window_size // 2\n",
        "    self.vocab = vocab\n",
        "    self.flatten_tokens = flatten_tokens\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.flatten_tokens) - self.window_size * 2\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = self.flatten_tokens[idx: idx + self.window_size] + self.flatten_tokens[idx + self.window_size + 1: idx + 2 * self.window_size + 1]\n",
        "    x = [self.vocab[el] for el in x]\n",
        "    y = self.flatten_tokens[idx + self.window_size]\n",
        "    y = self.vocab[y]\n",
        "    return torch.tensor(x).long(), torch.tensor(y).long()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYxZeW91q1VL"
      },
      "source": [
        "# Definindo perplexidade\n",
        "\n",
        "A perplexidade pode ser definida como sendo o exponencial da entropia cruzada total. Poderia ser aplicado diretamente ao código, porém, por uma questão de facilidade de leitura do loop de treino, validação e teste, optei por criar uma função com o nome apropriado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmk-HgdKq3cI"
      },
      "source": [
        "def perplexity(crossentropy_sum):\n",
        "  return math.exp(crossentropy_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ6LVBAyViSo"
      },
      "source": [
        "# Loops de treino, validação e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tonhB0jmWI7n",
        "outputId": "d83c89b8-aba6-4c6f-9be0-271278438ea2"
      },
      "source": [
        "run = neptune.init(\n",
        "    project=\"pedro.gengo/IA-376\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxZjYyNDA1MS1hZDJlLTRiZDctYjIxNy0xMTNhY2FmNzZhYmIifQ==\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/pedro.gengo/IA-376/e/IA-15\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT-vQ0Q1n2yh",
        "outputId": "779a7fe3-9039-4872-ad16-0cad171a4896"
      },
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   print(torch. cuda. get_device_name(dev))\n",
        "else: \n",
        "   dev = \"cpu\" \n",
        "print(dev)\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cc_xeG_n3OA"
      },
      "source": [
        "def train(model, train, valid, criterion, optimizer, filename_save, len_tokens_valid, n_epochs=10):\n",
        "  \n",
        "  best_valid_loss = 10e9\n",
        "  best_epoch = 0\n",
        "  train_losses, valid_losses, valid_perplexities = [], [], []\n",
        "  for i in range(n_epochs):\n",
        "    accumulated_loss = 0\n",
        "    model.train()\n",
        "    for x_train, y_train in train:\n",
        "      x_train = x_train.to(device)\n",
        "      y_train = y_train.to(device)\n",
        "      outputs = model(x_train)\n",
        "      batch_loss = criterion(outputs, y_train)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "      accumulated_loss += batch_loss.item()\n",
        "    train_loss = accumulated_loss / len(train.dataset)\n",
        "    run[f\"{filename_save}_train/loss\"].log(train_loss)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Laço de Validação, um a cada época.\n",
        "    accumulated_loss = 0\n",
        "    accumulated_accuracy = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x_valid, y_valid in valid:\n",
        "            x_valid = x_valid.to(device)\n",
        "            y_valid = y_valid.to(device)\n",
        "\n",
        "            # predict da rede\n",
        "            outputs = model(x_valid)\n",
        "\n",
        "            # calcula a perda\n",
        "            batch_loss = criterion(outputs, y_valid)\n",
        "\n",
        "            # calcula a acurácia\n",
        "            accumulated_loss += batch_loss.item()\n",
        "    \n",
        "    valid_loss = accumulated_loss / len_tokens_valid\n",
        "    run[f\"{filename_save}_valid/loss\"].log(valid_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    valid_perplexity = perplexity(valid_loss)\n",
        "    run[f\"{filename_save}_valid/ppl\"].log(valid_perplexity)\n",
        "\n",
        "    print(f'Época: {i:d}/{n_epochs - 1:d} Train Loss: {train_loss:.6f} Valid Loss: {valid_loss:.6f} Valid Ppl: {valid_perplexity:.3f}')\n",
        "\n",
        "    # Salvando o melhor modelo de acordo com a loss de validação\n",
        "    if valid_loss < best_valid_loss:\n",
        "        torch.save(model.state_dict(), filename_save + '.pt')\n",
        "        best_valid_loss = valid_loss\n",
        "        best_epoch = i\n",
        "        print('best model')\n",
        "\n",
        "  return model, train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHrhLLiJoCvF"
      },
      "source": [
        "def predict(model, state_dict, test, tokens_test):\n",
        "  accumulated_loss = 0\n",
        "  model.load_state_dict(torch.load(state_dict + '.pt'))\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for x_test, y_test in test:\n",
        "          x_test = x_test.to(device)\n",
        "          y_test = y_test.to(device)\n",
        "\n",
        "          # predict da rede\n",
        "          outputs = model(x_test)\n",
        "\n",
        "          # calcula a perda\n",
        "          batch_loss = criterion(outputs, y_test)\n",
        "          \n",
        "          accumulated_loss += batch_loss.item()\n",
        "\n",
        "  total_loss = accumulated_loss / tokens_test\n",
        "  ppl = perplexity(total_loss)\n",
        "  print('*' * 40)\n",
        "  print(f'Perplexidade de {ppl:.3f}')\n",
        "  print('*' * 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM2N_VvVoDFi"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "O modelo aqui definido é baseado na arquitetura CBOW, que podemos ver na figura abaixo. De forma resumida, temos uma camada de projeção, que é nossa cada de embeddings, seguida por uma camada de classificação (camada linear).\n",
        "\n",
        "![cbow.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4REQRXhpZgAATU0AKgAAAAgABAE7AAIAAAAXAAAISodpAAQAAAABAAAIYpydAAEAAAAuAAAQ2uocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHBlZHJvIGdhYnJpZWwgbG91cmVuY28AAAAFkAMAAgAAABQAABCwkAQAAgAAABQAABDEkpEAAgAAAAM5NQAAkpIAAgAAAAM5NQAA6hwABwAACAwAAAikAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMTowOToyMSAyMTozODoxNgAyMDIxOjA5OjIxIDIxOjM4OjE2AAAAcABlAGQAcgBvACAAZwBhAGIAcgBpAGUAbAAgAGwAbwB1AHIAZQBuAGMAbwAAAP/hCylodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTA5LTIxVDIxOjM4OjE2Ljk0NTwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5wZWRybyBnYWJyaWVsIGxvdXJlbmNvPC9yZGY6bGk+PC9yZGY6U2VxPg0KCQkJPC9kYzpjcmVhdG9yPjwvcmRmOkRlc2NyaXB0aW9uPjwvcmRmOlJERj48L3g6eG1wbWV0YT4NCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVuZD0ndyc/Pv/bAEMABwUFBgUEBwYFBggHBwgKEQsKCQkKFQ8QDBEYFRoZGBUYFxseJyEbHSUdFxgiLiIlKCkrLCsaIC8zLyoyJyorKv/bAEMBBwgICgkKFAsLFCocGBwqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKv/AABEIAXsBYgMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/APpGiiigAooooAKKKKACiiigAoqAXtszIq3EZMjFUG4fMR1Aomvba38zz7iOPygGfcwG0HoTQBPRVWHVLC4R2gvIZFjG5yrg7R6mpXuYY4lkeVFRyArE8HPSgCWiqH9u6Vv2f2hbbs4x5gzV+gAooooAKKKqXOq2FnN5V1eQwyYzsdwDj1oAt0VVn1Sxtlja4u4Y1kGULOBuHtUkV5bT25nhnjeIdXVgQPxoAmoqraalZX5YWV1DOU+8I3BxUst1BCxWWZEKoZCGbGFHU/SgCWiqcGsadczLFb3sEsjdFVwSaU6pYC8FobyEXB/5Zbxu/KgC3RVCTXNLilaOXULdHUkFTIAQatJd28gcpNGwjALkMPlyMjP4UAS0VVtdTsb1nFndwzFPvBHBxUgvLY2puBPGYVzmTcNox15oAmoo60UAFFFFABRUVxcw2kJmupUijXqztgCo4tRsp7U3MN1E8I6yK4IH40AWaKjkuIYdvmyqm/7u44z3qomu6VJII49Qt2diAFEgySaAL9FU01jTpZvJjvrdpM42iQZz6VYSeJ9+yRW8skPg/dPvQBJRVGTW9MhIEt/bpuGRukAyKtW9xDdQiW2lWWNujIcg0ASUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeSppj6r/AGPBBM0Fwt/eSQyqfuuoJU/TNRapqsmsW/iR5oAl5DbWUFzA/AEqzNkfQ5BB9DXqsemWMLxvDZwI0bMyFYwCpb7xHoT3pJdJ06aSd5rG3d7jb5zNEpMm05XdxzjtmgDi9W8O6jNBe6jNp2m6YtvplzEIrCQu05df4vkUYGOOvWpdUure68KeGo4JY5WmurfYqsDuwDn8q7o89ay7Pwzoen6g19Y6TZ2902czRwKrc9eQKAMMaVp5+JhU2Ftt/s0tjyVxnzF56da7CovssH2v7V5Mf2jZs83aN23OcZ649qloAKKKKACuEvbe6uPiTqgs9J0/Ucada7vt0uwJ883T5Gznv06V3dRLawJdSXKQxrPIqo8oUbmUZwCe4GT+ZoA84Og32laxoOnx2un39wltdSGG4crCu5wdqnaxwM4HA49KpxrnT7ya9SGxjm1WGPUrCAFUt0Bwc9MhupOMYr1NrWB7pLl4Y2njUqkpUblB6gHtnFRtp1k800r2kDSXCBJnMYzIvox7igDl9fjsNM8QeH5tMjht7nz28wQKButhGxfIHVRgH64rM8V3UF/fXt1aSCWGXwzNIjjurNlT+Ndnp3h/SNId30zTbW1aQYdoYgpI9OO1Ja+HNGsY7mO00u0hS6G2dUhUCQehGORyePegDA0fT9Tg0yOY6do0WLUmOS2B83dt46oP51W0q38Of8K9hu9XSLH3ricD97527nkfNuz+NdHaeE/D1hdJc2Oh6dbzxnKSxWqKy/QgcVIfDeinUv7QOlWf2zdu8/yV3Z9c46+9AGFqumafJ8QNAzY25EsF0z7oR85wnJyOT9axNaAj1LXkP7uyOp2aXWOFEPkpkH0GdoPtXoz2sElzFcSQxtPCCI5CoLID1APbOBTTY2ha4Y20Obn/AF52D97xj5vXgY5oA5LxHbWNnqmhnR4oYbt5SoEChS0G07s46r0rjZXm8PfDy5Dl30zV4pgCefIuN7AD/dbGPrj1r1XT/D2j6VI76bplravIMM0USqSPTjtU76XYS6f9hksrd7T/AJ4NECnXP3enXmgCxH/qk/3RTqAMDA6UUAFFFFAHK6+kM/jfQ4NUCtYtFOY0k5R7gFNoIPBO3dj8a53xdDDb6nq8WkoiQ/YEkvUiACq4kGCQOAdv6V6JfafaanatbahbRXMDcmOVAyn8DUVlo+nabaNa2Fjb28D53xxxhVbPqO9AHPazPBd6x4VihkjmLzmTapDZTyjk/Sk0zS9PX4jawFsbYCOytWQCFflO6XkccHgVuab4b0XR7h59L0u0tJZOGeGFVJ9sgVeW1gS6kuUhjWeRQryhRuYDOAT3AyfzoA800PQb/W/CotodM0uKKS6kI1B5SZ1AmJyFEfXjA+atzRZ4bOHxVFcTojRXMjNvYA4K8E/WuvtrWCzhENpDHDECSEjUKAScnge5qjf+GtE1S8S71HSrO6uExtllhVmGPcigDirjT7V/h/4dlntIWla6tAXeMFiplHGcdMGvRIIIbaIRW0SRRjokahQPwFNmtLa4iSOeCORI2VkV0BClTkED1BHFTUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAVLxPNubaNmcKxbIRyuePal/s+D1m/8CJP8aW4/wCP60+r/wDoNWaAKv8AZ8HrN/4ESf40f2fB6zf+BEn+NWqKAKtgNqzpuYhZiF3MWIGB3NWqrWf3rn/ru38hVmgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACq0+o2dtK8dxcxxvHEZnVmxhB/F9OKs1yvjHQb3Vp7GTTUViSbe6ywX9wxUseev3cY/wBqgDVvfEWnWlibhbhJSYhLGiNkyKTgEfU1HpfiS11LWbzSl+S7s40aVM55Ycj8OPzrjV8M6jpWi3M19GCtncwrbhWDFraNs9vXOcV0UWmXk/iPVZInuLW2vooJIb63ZD93OVwc9cjtQBY1rxJd6VLdvFpUk9pYxCW4nLhBg5JCA/eIAzWhaaxHc6o9kUKN5KzxE/8ALRD3/A5Fcvrdr4hudWjs5tJutU0a1RCClzAhu5OpMmWX5RxwByfatba1148tnjTYLOwImH90uRheO4Az+NAG1cf8f1p9X/8AQas1WuP+P60+r/8AoNWaACiiigCtZ/euf+u7fyFWaxbS6ltdbuILhswXUreQ2PuuAMr+I5H0raoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooARgGUqwBBGCD3oRFjQIihVUYAAwAKWigApqxojMyIqs5yxAwWPTmnUUAVrj/j+tPq/wD6DVmq1x/x/Wn1f/0GrNABRRRQBmS2Qv7O7hLFH88tG46o4wQw+hqfS71r2zzMoS4iYxzoP4XHXHseCPYin2f3rn/ru38hVK//AOJZqSakvEEuIbsegz8kn4E4Psc9qANaiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAr3MEkskUkMgRoyTyM5yMU3y73/AJ7x/wDfFWqKAKvl3v8Az3j/AO+KPLvf+e8f/fFWqKAILWB4FfzHDs7lyQMVLLEk8LxTKHjdSrKehB6inUUAZmkyvA8mmXLFpbYDy3brJEfun6jGD7itOs7V7eTZHfWi7rm0JZVHWRD95PxAyPcCrltcR3drHcQMGjkUMpFAEtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFe5mljlhjgClpCeW7YGaT/AE7/AKYfkf8AGi4/4/rT6v8A+g1ZoArf6d/0w/I/40f6d/0w/I/41ZooAgtZpJlk80KGRyh29DU9VrP71z/13b+QqzQAVk2//Er1ZrU8Wt2S8Poj/wAS/j1Fa1VdRshfWbRZ2uPmjcdUYdDQBaoqnpl6b20zKNs8TeXMn91h/Q9fxq5QAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUVz3iHxLJoV2Y2t1kSS0eSA7sF5VYDZ+O5f1oA6GiuEl8bXWo6WgsoVgkmihR33ZMMsjY2/gMmrmn6vcab4l1mPV7yJNMtEgSJnZiykg9eO+OfwoA6+iuS8SXd/JdaHeadqKx6bNeQqY4kO6bdu6tn7uAOMc+taP2uW08bCzMjPBe2plVWOdjocHHoCCOPXNAGncf8f1p9X/8AQas1WuP+P60+r/8AoNWaACiiigCtZ/euf+u7fyFWaxFvp9OvLmS6UPp7TEeag+aA4H3h3X3HTvxyNpWDqGUhlIyCDwRQAtFFFAGTff8AEs1FNRXi3lxFdDsB/C/4Hr7EntWtTJYknheKVQ6OCrKRkEGs/SJXgaXS7li0tqAYnY5MsJ+63uRgqfcZ/iFAGnRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABWbrGg2etm0N8rE2k4nj2nHI7H26flWlRQBzVx4NtIdKvodMzHPc3AugzHOJAcj8K0bTR1i1WbVHZ1muoUWeDIMe5eh+oyRWpRQBT1DTINSW2WfcBbTrOm04+Zc4/Dmqy6bLL4pfU7jaI4YBBbqDzycsx/QfhWrRQBWuP8Aj+tPq/8A6DVmq1x/x/Wn1f8A9BqzQAUUUUAVbQBvtQYZBmbIP0FUWim0JjJao02nE5kgXloP9pPVfVfxHob9n965/wCu7fyFWaAGQzx3MKywOskbjKspyDT6yZ7ObTZmu9LTfGxzNaDo3+0no3t3q/aXkN9brNbvuU/mD6EdjQBPWdq9vJtivrRS11aEsqjrIh++n4gAj3C1o0UARW1xHd20c8Dbo5FDKR3BqWsm3/4lerNani1uyZIPRH6sn49R+PpWtQAUUVm6rrlrpMkEUyTTTz7jFBbxmR2Axk4HYZH50AaVFZEHifTbiG2dHkU3E/2dUeMhlk7qw7dKdqniPTtHedb6RlMFs10+1CcRg4J/XpQBq0Vj3vinSrDw2mu3E5FjIqsrhSSdxwOK1wQygjoRmgBaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCpdkpc20ux2VS27YpbGR6Cnfbk/55XH/fh/8Ks0UAVvtyf88rj/AL8P/hR9uT/nlcf9+H/wqzRQBVsclZnKMoeUsoZSDjA7GrVFFABWbd2EsVw19pe1bg/6yInCTj39D71pUUAVbC/iv4S0e5JEO2SJxho29CKtVQv9OaaZbuxkFveoMLJjKuP7rjuP1HanWGpLeF4Zozb3cX+tgY5K+4P8Snsf5HIoAfqNkL+yaLdscENG/wDccdDTdMvTe2eZV2TxsY5k/uuOtXKyb7/iWakuorxBLiO6Hp/df8Oh9qANauT8Xi0GpWMt895YBEfytUtf+WTEjKMMEYOAeeOK6yigDzf7RfNpttqN0sl5a2OqiQXSWpR5osEGQoBk4J69+tM1+5XxI+s32lRTT2kektb+Z5TKHdmB2rkc8CvS6KAPJ9Z06+k0fVdFNrMbXTIZrqBghxIZV+RR64Ly8dsCvVouIU/3RTqKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACqd/pyXoSRHMNzFzFOn3l9vcHuKuUUAZ9jqLvMbPUEEN4ozgfdlH95f8O1XZYknheKVdyOCrA9xUN9YxX8ISXKspyki8Mh9QaqW97LBMLDVTtlcERXC8LMP6N7UAcxrvxI0H4e2Etr4kvf9It8C3hT5pJkP3ePUYwc+me9dgmqWkkMUqy5WaNZUwCcq3Q8V8l/Gz4W6ho3iK91fTr+TWLY4muUeTfPaBicFh125Bwa9++DGtf298NtEui2549Pitn9cxO8fP/fOfxoA7j+0bX/nof8Avhv8KP7Rtf8Anof++G/wqzRQBW/tG1/56H/vhv8ACp4pEmiWSJtyOAyn1Bp1VtN/5Bdr/wBcl/lQBZooooAKKKKACiiigAooooAhnuVgdV2O7N0CDNM+2n/n1uP++P8A69En/ISh/wBxqs0AVvtp/wCfW4/74/8Ar0fbT/z63H/fH/16s0UARwTrcR70DDnBDDBBqSq1j/q5P+urVZoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK53x3c6jaeDb6XRdHfWL1U/c2yMAd3ZuSDx1459K6KigD4f8K+Ptc8IfFQ6v4rW6ke4byNUt7tCGeFuCCrenUD2r658HeH9G0D7UvhrA02+CXkKI2Y1D5Pyf7J6496t+JPBnh7xfafZ/EWlW96uMKzp86f7rDlfwNQeEvDUHhK2Oj2NzcT2dvEv2cXDbmiQs5CZ6kDnGe3FAHR0UUUAFVtN/5Bdr/wBcl/lVgkKpZiAAMkntWVp2s6WNMtgdSswREuQZ19PrQBrUVS/trSv+gnZ/+BC/40f21pX/AEE7P/wIX/GgC7RVL+2tK/6Cdn/4EL/jR/bWlf8AQTs//Ahf8aALtFUv7a0r/oJ2f/gQv+NH9taV/wBBOz/8CF/xoAu0Vx3xB8dweFPAepa3pVxY3d3aKjRwNKGD5kVSMA56E1574Z/aj8Oajsi8R6fcaVKeDJGfNj+vYj9aAPapP+QlD/uNVmsDRPFGi+KJobrQNSgvoghyYm5X6jqPxrfoAKKKKAK1j/q5P+urVZrPWOSXTbuOCQxSMXCOvVT2NedDxnrUjrKJmCTW40pV2/d1D5ct/wCPH/vmgD1CS5gik2SzRo+N21nAOM4z+dOSaOVnWORHKHDBWB2n0PpXm+twyXek+IZLm5lSeG+t4PMDYIRdmPwyS31NdNbk2vjqOGGQyJcadvlJOdzKwAY++KAOlooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACmySpDGXldUQdWY4Ap1cf8SNEtvFfha48P+ZOL24XMAt3IZWHRm5xt9c0AUPFPxr8E+Fd8dzqqXdyvH2e0/eNn3xwK3PCGt3PiOyXVrrT304XUCSQwStlxGWfaW9CRzj3FfMPw2+EcyePL6bx1GtlpHh1/MvHnO2OVhyq5PVT1Pt9a+l/BPi2y8aJd6npETrp6kQW8jLt85UZgXA7DOQPpQB1VFFFAARkYPIqhp1pb/2Xbf6PF/ql/gHpV+q2m/8AILtf+uS/yoAf9ktv+feL/vgUfZLb/n3i/wC+BU1FAEP2S2/594v++BR9ktv+feL/AL4FTUUAQ/ZLb/n3i/74FH2S2/594v8AvgVNRQBzHjzwdH4x8EajoMDRWj3ioon8sHZh1Y9PZcVxPhj9m/wZoeyXU0l1i4Xkm4OEz/ujivXaKAMqy0qw0i4t7fS7OG0hWNgEhQKP0rVqtJ/yEof9xqs0AFFFFAFax/1cn/XVqBptkAALWLCzGcfIOJP73196LH/Vyf8AXVqs0AZr6HayahdzyKHivEVZ4GXKuV4DfXGB+Ap9npENpqM94py8iLGgxxGg/hFX6KACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAopk08VvC0s7rHGoyzMcAVlf6Trn/PS004/8BkuB/NV/U+3IoAfPqE17M1ro+0lTtlu2GY4vUD+83t0Hf0qza2MWm28jQI80zDc7sQXlb3J//UKswwRW0KQwIscaDCqowAKivryOxs3nl5CjhR1Y9gPegD44+Nfj7xb4h8STaRrtlPoljA+YtOPG/nh2YcP+HA7etfTnww0L/hG/A+jaWV2SRaZA8q+kjl3f/wAeY1Z1LwFovinTCnivT4by4lcSs7D5oj2VW6gAccdefWukls7adg00EbkDALKDgUATUVW/s2y/59Yf++BR/Ztl/wA+sP8A3wKALNVtN/5Bdr/1yX+VH9m2X/PrD/3wKnRFijVI1CoowqgYAFADqKKKACiiigAooooAKKKKAKdxLHFqMJldUGxuWOKm+2W3/PxF/wB9ipWRX+8oP1FN8mL/AJ5r+VADPtlt/wA/EX/fYo+2W3/PxF/32Kf5MX/PNfyo8mL/AJ5r+VAFfT2V4ZGQhlMrYIOc1bpFUKMKAB6CloAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAK9zNMk0McATMhOS+eMDNJi+9YPyNFx/x/Wn1f/0GrNAFbF96wfkaMX3rB+RqzRQBBaTSSrIJgoZJCny9D0qeq1n965/67t/IVZoAKq32oQ2CL5mXkc4jiQZZz6AVBd6k32g2WmoJ7sY35PyQg93P8h1P05qSx01bV2nmc3F2/wB+Zx+ijsPagCCHT5ryZbrV8EqcxWwOUj9z/eatSiigArJi/wCJtqvnHm0s2Ij9JJO7fQfzqTVbiRvL0+0bFxc5BYf8s0/ib+g9/pV22t47S2jggXbHGu1RQBLRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFZuoa9ZaZcSQ3jOrR2zXJIXIKKcHHqfb3FAGlRXOXfjOxXT1msd00s0CSwqVwDvOFB989qLDxQW1rU7DUo/s6afHEWuXG1GZgc8k+vT8aAOjorF07xNbavor32mr9plXd/o0UgL8MVH0zjP0rPsfEmoT+D5NYubeOOa3uJFmhU5ARZCpAPqAM/hQB0Nx/x/Wn1f8A9BqzVNpVnuLGWM5SQMyn2K1coAKKKKAKtowX7UzEACZiSe3Aqkbu51ljHpjtb2fR7zHzSe0YP/oR/AHOQ1NOe/vLn7ZLus1mO23UYDnA++e49ulbAAVQFAAHQDtQBDaWcFhbiC1jCIOeuSxPUknkk9STyanoooAKiurmKztZLi4bbHGu5jjP5ep9qlrJf/ib6t5Y5srFwX9JZuoH0Xr9SPSgCXSraX95fXq7bq6wSvXyk/hQfTv6kk960aKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5/xR4bk16SweCdYTby/vdwP7yIkFl/EqtdBRQBwTeDLnStHvXjkW5kS6jnt0QH5YozkJ+Wa3rPSXl1y/vZkgn0/UYYiEkGWVlz1UjGPm/St+igDO0TQ7PQrFbayiRcFiXCAM2WLc49M1i3OlXGl+C73Thiee8nlWMRg/wDLVyf0B/SurooAz4bf7INNt858pCmfXCYrQqtcf8f1p9X/APQas0AFFFFAFaz+9c/9d2/kKs1Ws/vXP/Xdv5CrNABRRTJZUgheWVgqICzE9hQBT1W7khiS3tMG7uTsiz0X1Y+wHNWLK0jsbOO3hztQdT1Y9ST7k5NU9Kie4lfVLlSsk42wof8AlnF2/E9T+HpWnQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBVu963FvKkTyhC24JjIyPc0v2x/wDnzuPyX/4qrNFAFb7Y/wDz53H5L/8AFUfbH/587j8l/wDiqs0UAVrIPtmaSNo98pYK2M4wPSrNFFABWTd/8TXUhYrza25D3J7O3UJ/U1Z1S9aztgIAHuZm8uBPVj3+g6n6U/T7JbCzWIEu5O6Rz1dj1JoAtUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUART3KW+wOHJc4UIhYn8qj+3p/zxuP8Avw3+FFx/x/Wn1f8A9BqzQBW+3p/zxuP+/Df4Ufb0/wCeNx/34b/CrNFAEcE6XCFo9w2ttIZSpB+hp5IVSzHAAySe1V7P71z/ANd2/kKpakTqd4ukx/6nAkvWH/PPtH/wIjn/AGQ3TIoANMB1G6bVpQfLYbLRT2j/AL31br9MVrUAAAAcAUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRVK71eysZpIrqcRvHAbhgeyDqf0oAu0ViXvirTrew8+CUTu8KzRIv8YY4X8zTdN8TxXmtX+mTp5M1jHG0jH7pLDkAn0oA3aKxjr/2zQft+iW5vZXfy44Qcc79hLegGCfoKz4/FN5DHqC39nCJtNkj88wOWQowByPcZ5BoA6C4/wCP60+r/wDoNWaqSOst1ZOhyrbiD6grVugAooooAy5b0WFrdSBTJI05WKMdXY4wKsaZZGytSJWD3ErGSeT+85/oOAPYCqdlZyTazc3VzgxwysLdPQkDLH37D8a2KACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5nxd4dutamsJLFkUo/lXO443QMVLD/AMdH5mumooA86/4RO+0jRbuafbN9muYnt0Q5P2eM5A+vOa6C30g3mu6nNdW0dxpmpQwvHJvHVc8Edf4gc10tAGBgcCgDkh4ZuvDnhSW18JxQtqUhI89/k+UuTnnPIBwKqC1vNN8F6hZXemJbTXI8pGW4857iR+CzHA57/hXcUEA9RnHSgDOgga1TS7dzloo9hPuExWjVa4/4/rT6v/6DVmgAooooArWf3rn/AK7t/IVZqtZ/euf+u7fyFWaACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAqXTql7aF2CjL8k4/hqf7RD/z2j/76FOeKOUASIr46bhnFM+y2/wDzwj/75FAC/aIf+e0f/fQo+0Q/89o/++hSfZbf/nhH/wB8ij7Lb/8APCP/AL5FAEViwb7QVII89uQfYVapqRpGu2NVUeijFOoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9k=)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEWOBqaQoFhy"
      },
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "  def __init__(self, emb_size, vocab_size):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.embedding = torch.nn.Embedding(vocab_size, emb_size)\n",
        "    self.linear = torch.nn.Linear(emb_size, vocab_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x).sum(dim=1)\n",
        "    x = self.linear(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uVnTAdcuwLE"
      },
      "source": [
        "# Experimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvLtQoHZ8fNk"
      },
      "source": [
        "## Hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COK3szgY12nH"
      },
      "source": [
        "learning_rate = 0.001\n",
        "n_epochs = 10\n",
        "batch_size = 128\n",
        "emb_size = 300\n",
        "window_size = 5\n",
        "\n",
        "hprams = {\"learning_rate\": learning_rate,\n",
        "          \"window_size\": window_size,\n",
        "          \"batch_size\":batch_size,\n",
        "          \"emb_size\": emb_size}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJh_88LL3hUw"
      },
      "source": [
        "## Validando o fluxo\n",
        "\n",
        "Utilizando apenas um pequeno conjunto do dataset completo, irei excutar o fluxo de treino completo para validar a execução e comportamento dos resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MItkw2I7uxxH"
      },
      "source": [
        "dataset_train = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_train[:100], vocabulary))\n",
        "dataset_valid = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_valid[:50], vocabulary))\n",
        "dataset_test = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_test, vocabulary))\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgw3FTzK15Xk",
        "outputId": "af3f8da7-1834-46a9-86ba-7d04b8537223"
      },
      "source": [
        "cbow = CBOW(emb_size, len(vocabulary))\n",
        "cbow.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embedding): Embedding(10000, 300)\n",
              "  (linear): Linear(in_features=300, out_features=10000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6PIoZWtxKVy",
        "outputId": "c9dc2fbf-40a3-4231-9acc-106503ba6c64"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(cbow.parameters(), lr=learning_rate)\n",
        "\n",
        "_ = train(cbow, dataloader_train, dataloader_valid, criterion, optimizer, 'cbow', len(unify_text(x_valid[:50], vocabulary)), n_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época: 0/9 Train Loss: 7.863433 Valid Loss: 7.448103 Valid Ppl: 1716.603\n",
            "best model\n",
            "Época: 1/9 Train Loss: 5.412900 Valid Loss: 7.356866 Valid Ppl: 1566.919\n",
            "best model\n",
            "Época: 2/9 Train Loss: 4.105319 Valid Loss: 7.465791 Valid Ppl: 1747.237\n",
            "Época: 3/9 Train Loss: 3.278065 Valid Loss: 7.619134 Valid Ppl: 2036.797\n",
            "Época: 4/9 Train Loss: 2.768173 Valid Loss: 7.771484 Valid Ppl: 2371.989\n",
            "Época: 5/9 Train Loss: 2.401448 Valid Loss: 7.920948 Valid Ppl: 2754.380\n",
            "Época: 6/9 Train Loss: 2.123911 Valid Loss: 8.075565 Valid Ppl: 3214.943\n",
            "Época: 7/9 Train Loss: 1.899094 Valid Loss: 8.217910 Valid Ppl: 3706.747\n",
            "Época: 8/9 Train Loss: 1.713157 Valid Loss: 8.365670 Valid Ppl: 4296.990\n",
            "Época: 9/9 Train Loss: 1.551892 Valid Loss: 8.519005 Valid Ppl: 5009.068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lsiDy5R3e6X"
      },
      "source": [
        "## Experimento final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45rz7Moy3m-R"
      },
      "source": [
        "dataset_train = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_train, vocabulary))\n",
        "dataset_valid = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_valid, vocabulary))\n",
        "dataset_test = DatasetSlidingWindow(window_size, vocabulary, unify_text(x_test, vocabulary))\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-PEZgYT3rjD",
        "outputId": "51971798-97e8-4c9d-8f25-d482a3131934"
      },
      "source": [
        "cbow = CBOW(emb_size, len(vocabulary))\n",
        "cbow.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embedding): Embedding(10000, 300)\n",
              "  (linear): Linear(in_features=300, out_features=10000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSqMOY_i3svf",
        "outputId": "bfc3bd2b-fe29-4781-8074-9ef53d1021c9"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(cbow.parameters(), lr=learning_rate)\n",
        "\n",
        "_ = train(cbow, dataloader_train, dataloader_valid, criterion, optimizer, 'cbow', len(unify_text(x_valid, vocabulary)), n_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época: 0/9 Train Loss: 5.632504 Valid Loss: 5.422756 Valid Ppl: 226.503\n",
            "best model\n",
            "Época: 1/9 Train Loss: 5.220908 Valid Loss: 5.326257 Valid Ppl: 205.667\n",
            "best model\n",
            "Época: 2/9 Train Loss: 5.075302 Valid Loss: 5.282997 Valid Ppl: 196.959\n",
            "best model\n",
            "Época: 3/9 Train Loss: 4.980142 Valid Loss: 5.259907 Valid Ppl: 192.464\n",
            "best model\n",
            "Época: 4/9 Train Loss: 4.910263 Valid Loss: 5.251431 Valid Ppl: 190.839\n",
            "best model\n",
            "Época: 5/9 Train Loss: 4.856976 Valid Loss: 5.248691 Valid Ppl: 190.317\n",
            "best model\n",
            "Época: 6/9 Train Loss: 4.815394 Valid Loss: 5.247158 Valid Ppl: 190.025\n",
            "best model\n",
            "Época: 7/9 Train Loss: 4.781734 Valid Loss: 5.248794 Valid Ppl: 190.337\n",
            "Época: 8/9 Train Loss: 4.755272 Valid Loss: 5.247340 Valid Ppl: 190.060\n",
            "Época: 9/9 Train Loss: 4.733733 Valid Loss: 5.250761 Valid Ppl: 190.711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea0KXpKTdkvF",
        "outputId": "93ac8556-a421-4755-8583-fc1ce4809e5e"
      },
      "source": [
        "predict(cbow, 'cbow', dataloader_test, len(unify_text(x_test, vocabulary)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************\n",
            "Perplexidade de 198.280\n",
            "****************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHKzJ1XadbRS"
      },
      "source": [
        "## Avaliação algébrica dos vetores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znh0mVLxeQgq"
      },
      "source": [
        "emb_weights = cbow.embedding.weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpgkW2hceVqF"
      },
      "source": [
        "def find_similar_embeddings(word_vector, n, emb_weights, vocab):\n",
        "  distances = []\n",
        "  for i in range(emb_weights.shape[0]):\n",
        "      sim = torch.cosine_similarity(word_vector, emb_weights[i], dim=0).item()\n",
        "      distances.append((vocab[i], sim))\n",
        "\n",
        "  return sorted(distances, key=lambda x: x[1], reverse=True)[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swtsf4R4iqA_",
        "outputId": "12a1240a-9abd-4f78-b853-191e4ca1ced4"
      },
      "source": [
        "vocab_idx_to_word = {value: key for key, value in vocabulary.items()}\n",
        "find_similar_embeddings(emb_weights[vocabulary['car']], 5, emb_weights, vocab_idx_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('car', 1.0),\n",
              " ('truck', 0.3475690186023712),\n",
              " ('plane', 0.3317131996154785),\n",
              " ('bus', 0.32689565420150757),\n",
              " ('train', 0.3259400427341461)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9GJIqHLiyg3",
        "outputId": "6602d14a-4794-4a87-d6f6-acc8fb2c0005"
      },
      "source": [
        "possib_queen = emb_weights[vocabulary['king']] - emb_weights[vocabulary['man']] + emb_weights[vocabulary['woman']]\n",
        "find_similar_embeddings(possib_queen, 5, emb_weights, vocab_idx_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.7818091511726379),\n",
              " ('woman', 0.40075036883354187),\n",
              " ('dickens', 0.273348331451416),\n",
              " ('writer', 0.2671816051006317),\n",
              " ('wife', 0.248124361038208)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dyXHOxEjUP2",
        "outputId": "24835f87-df9f-46f1-f02a-99bcf95120dd"
      },
      "source": [
        "possib_queen = emb_weights[vocabulary['best']] - emb_weights[vocabulary['good']] + emb_weights[vocabulary['bad']]\n",
        "find_similar_embeddings(possib_queen, 5, emb_weights, vocab_idx_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('best', 0.7514254450798035),\n",
              " ('worst', 0.5503748655319214),\n",
              " ('bad', 0.38615408539772034),\n",
              " ('greatest', 0.382972776889801),\n",
              " ('scariest', 0.3725852370262146)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}